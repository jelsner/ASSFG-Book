# Statistical Uncertainty & Counts

When interpreting forecasts of counts, like the number of hurricanes expected this upcoming season, it is good to keep in mind the amount of statistical uncertainty. Statistical uncertainty can be large for small counts. I demonstrate this using the following code. First I create a vector of length equal to 140 years that has the rate varying predictably between 4 and 10. Then, from the rate for each year I generate a random count based on a Poisson distribution and compute the squared correlation between the count vector and the rate vector. This is the variation in counts explained by the rate (epistemic uncertainty). One minus this is the variation in counts unexplained by the rate [statistical (aleatoric) uncertainty]. Repeat 20000 times and generate a density curve.
```{r}
rate <- rep(4:10, 20)
eu <- numeric()
su <- numeric()
for(j in 1:20000){
  h <- rpois(length(rate), lambda = rate)
  eu[j] = cor(rate, h)^2 * 1
  su[j] = 1 - eu[j]
}

library(dplyr)
library(ggplot2)
library(scales)

data.frame(eu, su) %>%
  ggplot(aes(su)) +
  geom_density(size = 2) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1L)) +
  xlab("") + ylab("Density") +
  labs(title = "Percent variation in counts unexplained by the rate",
       subtitle = "For a range of rates between 4 & 10") +
  theme_minimal()
```